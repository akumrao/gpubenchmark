# -*- coding: utf-8 -*-
"""loggerWithTid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BmHEFp9UClOLkTiAnnHfMTjI0obOYMZI?resourcekey=0-tOjVsQPsBX2bkLfH8IsfOw

# Log files parsing
"""

import os
import re
import argparse

"""
Author : Chaithanya M
LDAP : mchaithanyaaa
Review 1 : Arvind Umrao

Requirements:
1. Parse each line of logs, let say ln
    1.1 If  tid token exist,  create file with tid value, for eg 100001.txt.  push the ln to 100001.txt
    1.2 If tid not available create file with name main.txt ,  push the ln to main.txt.
2. Concat main.txt  +  100001.txt  + 100002.txt etc

Input : path to input log file
Output : path to output folder

command to execute : python3 <file_name>.py <input_log_file> <output_folder>


"""


def split_and_concatenate_log(input_log_file, output_folder):

    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    tid_files = {} # Store file objects for each tid
    unrelated_lines = [] # Store lines without tid

    # Step 1: Parse log lines and write to appropriate files
    with open(input_log_file, "r") as file:
        for line in file:
            stripped_line = line.strip()

            timestamp_match = re.match(r"^[A-Za-z]{3}-\d{2}", stripped_line)

            if timestamp_match:

                # Check if the line contains a tid
                if ("tid =" in stripped_line or "ID:" in stripped_line) and "checksum" not in stripped_line:
                    # Extract tid, handle potential multiple values separated by commas
                    tid_part = stripped_line.split("tid =")[-1].strip() or stripped_line.split("ID:")[-1].strip()

                    # Split potential multiple tids and take the first numeric one
                    tids = [part.strip() for part in tid_part.split(",")]
                    tid = next((t for t in tids if t.isdigit()), None)

                    if tid is None: # Skip if no valid numeric tid is found
                        unrelated_lines.append(line)
                        continue

                    # Create a file for this tid if not already created
                    if tid not in tid_files:
                        tid_file_path = os.path.join(output_folder, f"{tid}.txt")
                        tid_files[tid] = open(tid_file_path, "w")

                    # Write the line to the tid-specific file
                    tid_files[tid].write(line)
                else:
                    # Add the line to unrelated_lines if no tid is found
                    unrelated_lines.append(line)

    # Write unrelated lines to main.txt
    main_file_path = os.path.join(output_folder, "main.txt")
    with open(main_file_path, "w") as main_file:
        main_file.writelines(unrelated_lines)

    # Close all tid-specific files
    for file in tid_files.values():
        file.close()

    # Step 2: Concatenate main.txt and all tid files into one file
    concatenated_file_path = os.path.join(output_folder, "concatenated_output.txt")
    with open(concatenated_file_path, "w") as concatenated_file:
        # Write main.txt content
        with open(main_file_path, "r") as main_file:
            concatenated_file.writelines(main_file.readlines())

        # Write content of all tid files
        for tid, file_path in tid_files.items():
            with open(file_path.name, "r") as tid_file:
                concatenated_file.writelines("\n")
                concatenated_file.writelines(tid_file.readlines())

    print(f"Files saved in folder: {output_folder}")
    print(f"Concatenated file created: {concatenated_file_path}")


if __name__ == "__main__":

    # split_and_concatenate_log("/content/logs_ufs.txt","/content/test")
    parser = argparse.ArgumentParser(description="Split and concatenate log files.")
    parser.add_argument("input_file", help="Path to the input log file.")
    parser.add_argument("output_folder", help="Path to the output folder.")
    args = parser.parse_args()

    try:
        split_and_concatenate_log(args.input_file, args.output_folder)
    except (FileNotFoundError, PermissionError) as e:
        print(f"Error: {e}")